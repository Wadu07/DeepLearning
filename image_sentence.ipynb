{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-13T16:58:30.928953Z",
     "start_time": "2024-12-13T16:58:30.925444Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:30:06.775730Z",
     "start_time": "2024-12-13T16:30:06.741952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "val = pd.read_csv('val.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train_images_path = './train_images'\n",
    "val_images_path = './val_images'\n",
    "test_images_path = './test_images'"
   ],
   "id": "27562ae2fe0ee19b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:07:40.377812Z",
     "start_time": "2024-12-13T16:07:40.371973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(train), len(val), len(test))\n",
    "print(train.head())"
   ],
   "id": "724cf164c6b1ac4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 3000 2000\n",
      "                                     id  \\\n",
      "0  417812c5-0ce4-499d-b97d-4d28827239bc   \n",
      "1  5ac91fa3-55f2-4cb3-8c8f-ad84f78e6b36   \n",
      "2  d2705b90-8347-4cab-a7a6-654540d9a489   \n",
      "3  a3b33fe7-3085-4433-9c18-8814803891b4   \n",
      "4  1514b0e4-0665-45bc-ab32-52fce326cc29   \n",
      "\n",
      "                                             caption  image_id  label  \n",
      "0  Wet elephants shake water onto people bathing ...    394330      0  \n",
      "1       Two men holding tennis racquets on the court    130849      0  \n",
      "2  A bird on a tree limb with mountains in the ba...    514790      0  \n",
      "3  A kitchen and dining room are featured along w...    182096      0  \n",
      "4     A fruit stand has various fruits on the table.     68788      1  \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading images...",
   "id": "64103db2a2d7225c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:14:42.946815Z",
     "start_time": "2024-12-13T17:14:38.325375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "folders = [\"train_images\", \"val_images\", \"test_images\"]\n",
    "image_data = []\n",
    "size_not = []\n",
    "grayscale = []\n",
    "for folder in folders:\n",
    "    files = [f for f in os.listdir(folder) if f.endswith('.jpg')]\n",
    "    for file_name in tqdm(files, desc = f\"Loading images from folder {folder}\"):\n",
    "        file_path = os.path.join(folder, file_name)\n",
    "\n",
    "        img = Image.open(file_path) #open the image\n",
    "        \n",
    "        if img.mode != \"RGB\":\n",
    "            img = img.convert(\"RGB\")\n",
    "            \n",
    "        img_arr = np.array(img)\n",
    "        image_data.append(img_arr)\n",
    "            \n"
   ],
   "id": "9f47e3f937d49d46",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images from folder train_images: 100%|██████████| 9463/9463 [00:02<00:00, 3241.18it/s]\n",
      "Loading images from folder val_images: 100%|██████████| 2957/2957 [00:00<00:00, 3246.37it/s]\n",
      "Loading images from folder test_images: 100%|██████████| 1978/1978 [00:00<00:00, 3232.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed images shape: (14398, 100, 100, 3)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:15:40.919614Z",
     "start_time": "2024-12-13T17:15:40.801791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_data = np.array(image_data)\n",
    "print(\"Loaded images shape:\", image_data.shape)"
   ],
   "id": "b0ee7e436c104e3f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded images shape: (14398, 100, 100, 3)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:29:45.752691Z",
     "start_time": "2024-12-13T17:29:45.606680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "\n",
    "def build_model():\n",
    "    ### 3.1. create the model\n",
    "    model = Sequential()\n",
    "    \n",
    "    ### 3.2. add the layers\n",
    "    \n",
    "    # L1: add a CONV layer with 32 filters, kernel size 3, padding same, activation relu \n",
    "    model.add(Conv2D(32, kernel_size=3, padding='same', activation='relu', input_shape=(100, 100, 3)))\n",
    "    \n",
    "    # L2: add a CONV layer with 32 filters, kernel size 3, activation relu\n",
    "    model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "    \n",
    "    # L3: add a Max Pooling layer, pool size 2x2\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    # L4: add a Dropout layer, drop 1/4 of the neurons\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    # L5: add a CONV layer with 64 filters, kernel size 3, padding same, activation relu\n",
    "    model.add(Conv2D(64, kernel_size=3, padding='same', activation='relu'))\n",
    "    \n",
    "    # L6: add a CONV layer with 64 filters, kernel size 3, activation relu\n",
    "    model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "    \n",
    "    # L7: add a Max Pooling layer with pool size 2x2\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    # L8: add a Dropout layer; drop 1/4 of the neurons\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    # L9: add a Flatten layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # L10: add a Dense layer with 512 neurons and activation relu\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    \n",
    "    \n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n"
   ],
   "id": "9982117e27850a18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 100, 100, 32)      896       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 98, 98, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 49, 49, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 49, 49, 32)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 49, 49, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 47, 47, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 23, 23, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 23, 23, 64)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 33856)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               17334784  \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17400352 (66.38 MB)\n",
      "Trainable params: 17400352 (66.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:29:55.396323Z",
     "start_time": "2024-12-13T17:29:49.757932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_extractor = Sequential(model.layers[:-1])  # Exclude last layer\n",
    "features = feature_extractor.predict(image_data)\n",
    "print(\"Extracted features shape:\", features.shape)"
   ],
   "id": "8157625116a3d3ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97/450 [=====>........................] - ETA: 14s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m feature_extractor \u001B[38;5;241m=\u001B[39m Sequential(model\u001B[38;5;241m.\u001B[39mlayers[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])  \u001B[38;5;66;03m# Exclude last layer\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m features \u001B[38;5;241m=\u001B[39m feature_extractor\u001B[38;5;241m.\u001B[39mpredict(image_data)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExtracted features shape:\u001B[39m\u001B[38;5;124m\"\u001B[39m, features\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pachet\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pachet\\Lib\\site-packages\\keras\\src\\engine\\training.py:2655\u001B[0m, in \u001B[0;36mModel.predict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   2653\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39msteps():\n\u001B[0;32m   2654\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_predict_batch_begin(step)\n\u001B[1;32m-> 2655\u001B[0m     tmp_batch_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict_function(iterator)\n\u001B[0;32m   2656\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   2657\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pachet\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pachet\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    829\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    831\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 832\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    834\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    835\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pachet\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:877\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    874\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    875\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[0;32m    876\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[1;32m--> 877\u001B[0m results \u001B[38;5;241m=\u001B[39m tracing_compilation\u001B[38;5;241m.\u001B[39mcall_function(\n\u001B[0;32m    878\u001B[0m     args, kwds, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config\n\u001B[0;32m    879\u001B[0m )\n\u001B[0;32m    880\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[0;32m    881\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    882\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pachet\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[1;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[0;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[1;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m function\u001B[38;5;241m.\u001B[39m_call_flat(  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m    140\u001B[0m     flat_inputs, captured_inputs\u001B[38;5;241m=\u001B[39mfunction\u001B[38;5;241m.\u001B[39mcaptured_inputs\n\u001B[0;32m    141\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pachet\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[0;32m   1319\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1321\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1322\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1323\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inference_function\u001B[38;5;241m.\u001B[39mcall_preflattened(args)\n\u001B[0;32m   1324\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1325\u001B[0m     args,\n\u001B[0;32m   1326\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1327\u001B[0m     executing_eagerly)\n\u001B[0;32m   1328\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pachet\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[1;34m(self, args)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcall_flat(\u001B[38;5;241m*\u001B[39margs)\n\u001B[0;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pachet\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[0;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mcall_function(\n\u001B[0;32m    252\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname,\n\u001B[0;32m    253\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[0;32m    254\u001B[0m         \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mflat_outputs),\n\u001B[0;32m    255\u001B[0m     )\n\u001B[0;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[0;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[0;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[0;32m    261\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pachet\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001B[0m, in \u001B[0;36mContext.call_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1484\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[0;32m   1485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1486\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute(\n\u001B[0;32m   1487\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1488\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   1489\u001B[0m       inputs\u001B[38;5;241m=\u001B[39mtensor_inputs,\n\u001B[0;32m   1490\u001B[0m       attrs\u001B[38;5;241m=\u001B[39mattrs,\n\u001B[0;32m   1491\u001B[0m       ctx\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1492\u001B[0m   )\n\u001B[0;32m   1493\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1494\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m   1495\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1496\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1500\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[0;32m   1501\u001B[0m   )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pachet\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     54\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:32:31.196470Z",
     "start_time": "2024-12-13T17:32:31.192148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ],
   "id": "6b343e17831778e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
